{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"About Resync","text":"<p>Resync is an open-source library that provides a synchronous API for performing parallel tasks with parallel Luau.</p> <p>Disclaimer</p> <p>Not all tasks benefit from parallelism. In some cases, parallelizing tasks can actually slow down your code due to the overhead of creating and managing threads. It is important to profile your code and determine if parallelism is the right solution for your problem.</p> <p>Info</p> <p>Basic understanding of parallel Luau is assumed in this documentation. If you are new to parallel Luau, it is recommended to read the official Roblox documentation.</p>"},{"location":"#benchmarks","title":"Benchmarks","text":"<p> Average sampling times over 1000 iterations for 4D Perlin noise generation with varying thread and noise octave counts. Samples with more octaves require more iterations of the Perlin noise function for a single sample. Unsafe benchmarks have Resync's thread synchronization mechanism disabled.</p>"},{"location":"api-reference/handlers/","title":"Server &amp; Client Handlers","text":"<p>In addition to the <code>ThreadPool</code> class, Resync contains two scripts for executing tasks on the server and client side. These scripts are called <code>ServerHandler</code> and <code>ClientHandler</code>, respectively.</p> <p>The server and client handlers are identical in functionality, the only difference being the context in which they are executed. The server handler is executed on the server, while the client handler is executed on the client. The scripts are responsible for the execution of tasks dispatched with Resync as well as communication between each thread and the thread pool. Modifying these scripts should not be necessary, as they are only used internally by the <code>ThreadPool</code> class.</p>"},{"location":"api-reference/threadpool/","title":"ThreadPool","text":"<p>A ThreadPool is a collection of threads that can be used to execute tasks concurrently.</p>"},{"location":"api-reference/threadpool/#constructor","title":"Constructor","text":""},{"location":"api-reference/threadpool/#new","title":"new","text":"<pre><code>(worker: ModuleScript, threads: number, queueType: QueueType?, allowDispatchingToBusyThreads: boolean?): ThreadPool\n</code></pre> <p>Creates a new ThreadPool using the specified worker module and number of threads. All threads are initialized automatically when the ThreadPool is created. Yields the current thread until all threads are initialized.</p> <ul> <li><code>worker</code> should be a ModuleScript that returns a function. When a task is dispatched, the function is called with the current thread's Actor, the thread worker's index (1-indexed), and any additional arguments passed to the dispatch method.</li> <li><code>threads</code> is the number of threads to create in the pool. Should be a positive integer.</li> <li><code>queueType</code> is an optional parameter that specifies the type of queue to use. If not provided, the default queue type is <code>\"FIFO\"</code>. Supported queue types are <code>\"FIFO\"</code> and <code>\"LIFO\"</code>.</li> <li><code>allowDispatchingToBusyThreads</code> is an optional parameter that specifies whether tasks can be dispatched to threads that are already busy. If not provided, the default value is <code>false</code>.   Setting this to <code>true</code> will disable Resync's Thread State Tracking feature, which can improve performance in some cases.</li> </ul>"},{"location":"api-reference/threadpool/#properties","title":"Properties","text":""},{"location":"api-reference/threadpool/#actors","title":"Actors","text":"<p><code>{Actor}</code></p> <p>Table of all the actors in the thread pool. Should not be modified.</p>"},{"location":"api-reference/threadpool/#allowdispatchingtobusythreads","title":"AllowDispatchingToBusyThreads","text":"<p><code>boolean</code></p> <p>Whether tasks can be dispatched to threads that are already executing a task. If <code>true</code>, tasks will be dispatched to the next initialized thread in a round-robin fashion even if the thread is busy. If <code>false</code>, busy threads will be skipped until an idle thread is found, or the thread pool will wait until a thread becomes available.</p> <p>Important</p> <p>Setting this property to <code>true</code> will disable Resync's Thread State Tracking feature, which can improve performance, but without it Resync will not guarantee that all threads have finished their tasks once the task queue is empty. Resync should still be able to keep track of this internally, but won't strictly enforce it.</p> <p>Experimental Feature</p> <p>This property may be removed in a future version of Resync if Resync's thread state tracking is found to be stable without this restriction.</p>"},{"location":"api-reference/threadpool/#autodispatch","title":"AutoDispatch","text":"<p><code>boolean</code></p> <p>Whether the thread pool should automatically dispatch tasks when they are added to the queue. Respects the <code>AllowDispatchingToBusyThreads</code> property.</p>"},{"location":"api-reference/threadpool/#poolid","title":"PoolId","text":"<p><code>string</code></p> <p>A unique identifier for the thread pool. Currently unused.</p>"},{"location":"api-reference/threadpool/#queuetype","title":"QueueType","text":"<p><code>QueueType</code></p> <p>The type of task queue to use for the thread pool. Supported queue types are <code>\"FIFO\"</code> and <code>\"LIFO\"</code>.</p>"},{"location":"api-reference/threadpool/#taskqueue","title":"TaskQueue","text":"<p><code>{{any}}</code></p> <p>Table of arrays containing the arguments to pass to the worker function when a task is dispatched. Should not be modified.</p>"},{"location":"api-reference/threadpool/#threadcontainer","title":"ThreadContainer","text":"<p><code>Folder</code></p> <p>The folder containing the actors and worker scripts for the thread pool. Should not be modified.</p>"},{"location":"api-reference/threadpool/#threadcount","title":"ThreadCount","text":"<p><code>number</code></p> <p>The number of threads in the thread pool. Should not be modified directly. Use the <code>Resize</code> method to change the number of threads.</p>"},{"location":"api-reference/threadpool/#worker","title":"Worker","text":"<p><code>ModuleScript</code></p> <p>The worker module used by the thread pool. Should not be modified.</p>"},{"location":"api-reference/threadpool/#workerstate","title":"WorkerState","text":"<p><code>SharedTable&lt;number&gt;</code></p> <p>A SharedTable containing the number of tasks each thread is currently running. Should not be modified. Only contains values for initialized threads.</p>"},{"location":"api-reference/threadpool/#_batchdispatchinprogress","title":"_batchDispatchInProgress","text":"<p><code>boolean</code></p> <p>Internal property used to track whether a batch dispatch is in progress. Should not be modified.</p>"},{"location":"api-reference/threadpool/#_lastdispatchedthread","title":"_lastDispatchedThread","text":"<p><code>number</code></p> <p>Internal property used to track the last thread that was dispatched to in order to maintain round-robin dispatching. Should not be modified.</p>"},{"location":"api-reference/threadpool/#_threaddoneconnection","title":"_threadDoneConnection","text":"<p><code>RBXScriptConnection</code></p> <p>Internal property used to be able to dispose of the connection to the <code>ThreadDone</code> event. Should not be modified.</p>"},{"location":"api-reference/threadpool/#methods","title":"Methods","text":""},{"location":"api-reference/threadpool/#add","title":"Add","text":"<pre><code>Add(...: any): void\n</code></pre> <p>Adds a task to the task queue. The task function will be called with the provided arguments. If <code>AutoDispatch</code> is <code>true</code>, the task will be dispatched immediately.</p>"},{"location":"api-reference/threadpool/#addbatch","title":"AddBatch","text":"<pre><code>AddBatch(batch: {{any}}): void\n</code></pre> <p>Adds multiple tasks to the task queue. Each element in the batch should be an array containing the arguments to pass to the worker function. If <code>AutoDispatch</code> is <code>true</code>, the tasks will be dispatched immediately.</p>"},{"location":"api-reference/threadpool/#clear","title":"Clear","text":"<pre><code>Clear(): void\n</code></pre> <p>Clears the task queue. Does not affect tasks that are currently running.</p>"},{"location":"api-reference/threadpool/#destroy","title":"Destroy","text":"<pre><code>Destroy(): void\n</code></pre> <p>Destroys the thread pool and all related objects. Clears the task queue and waits for all currently running tasks to complete before destroying the pool.</p> <p>Important</p> <p>Since the ThreadPool object references <code>Instance</code> objects, Roblox's Lua garbage collector will not collect the ThreadPool object until it is destroyed. It is important to call <code>Destroy</code> on the ThreadPool object when you are done with it to avoid memory leaks.</p>"},{"location":"api-reference/threadpool/#dispatch","title":"Dispatch","text":"<pre><code>Dispatch(...: any): number\n</code></pre> <p>Dispatches one task to the thread pool. The task function will be called with the provided arguments. Yields the current thread until the task has completed.</p> <p>Returns the ID of the thread that the task was dispatched to.</p>"},{"location":"api-reference/threadpool/#dispatchasync","title":"DispatchAsync","text":"<pre><code>DispatchAsync(...: any): number\n</code></pre> <p>Dispatches one task to the thread pool asynchronously. The task function will be called with the provided arguments. Yields the current thread until the task can be dispatched.</p> <p>Returns the ID of the thread that the task was dispatched to.</p>"},{"location":"api-reference/threadpool/#dispatchall","title":"DispatchAll","text":"<pre><code>DispatchAll(): number\n</code></pre> <p>Dispatches all tasks in the task queue to the thread pool. Yields the current thread until all tasks have been completed.</p> <p>Returns the number of tasks that were dispatched.</p>"},{"location":"api-reference/threadpool/#dispatchallasync","title":"DispatchAllAsync","text":"<pre><code>DispatchAllAsync(): number\n</code></pre> <p>Dispatches all tasks in the task queue to the thread pool asynchronously. Yields the current thread until all tasks can be dispatched.</p> <p>Returns the number of tasks that were dispatched.</p>"},{"location":"api-reference/threadpool/#dispatchnext","title":"DispatchNext","text":"<pre><code>DispatchNext(): number\n</code></pre> <p>Dispatches the next task in the task queue to the thread pool. Yields the current thread until the task has completed.</p> <p>Returns the ID of the thread that the task was dispatched to.</p>"},{"location":"api-reference/threadpool/#dispatchnextasync","title":"DispatchNextAsync","text":"<pre><code>DispatchNextAsync(): number\n</code></pre> <p>Dispatches the next task in the task queue to the thread pool asynchronously. Yields the current thread until the task can be dispatched.</p> <p>Returns the ID of the thread that the task was dispatched to.</p>"},{"location":"api-reference/threadpool/#dispatchtoallfreethreads","title":"DispatchToAllFreeThreads","text":"<pre><code>DispatchToAllFreeThreads(): number\n</code></pre> <p>Dispatches tasks to all free threads in the thread pool. Yields the current thread until all tasks have been completed.</p> <p>Returns the number of tasks that were dispatched.</p>"},{"location":"api-reference/threadpool/#dispatchtoallfreethreadsasync","title":"DispatchToAllFreeThreadsAsync","text":"<pre><code>DispatchToAllFreeThreadsAsync(): number\n</code></pre> <p>Dispatches tasks to all free threads in the thread pool asynchronously. Yields the current thread until all tasks can be dispatched.</p> <p>Returns the number of tasks that were dispatched.</p>"},{"location":"api-reference/threadpool/#getnextfreethread","title":"GetNextFreeThread","text":"<pre><code>GetNextFreeThread(): number?\n</code></pre> <p>Returns the ID of the next free thread in the thread pool. If no threads are free, returns <code>nil</code>.</p>"},{"location":"api-reference/threadpool/#getthreadstates","title":"GetThreadStates","text":"<pre><code>GetThreadStates(): (AggregatedThreadStates, {number})\n</code></pre> <p>Returns a tuple containing an <code>AggregatedThreadStates</code> table and a table listing the number of active tasks in each thread, or -1 if a thread hasn't been initialized. The <code>AggregatedThreadStates</code> table contains the total number of threads in each state.</p>"},{"location":"api-reference/threadpool/#resize","title":"Resize","text":"<pre><code>Resize(newThreadCount: number): void\n</code></pre> <p>Resizes the thread pool to the specified number of threads. If the new thread count is greater than the current thread count, new threads will be created. If the new thread count is less than the current thread count, threads will be destroyed. Waits until all currently running tasks have completed before resizing the thread pool. New threads will be initialized with the worker function from the original thread pool. Yields the current thread until all new workers are initialized.</p> <p><code>newThreadCount</code> should be a positive integer.</p>"},{"location":"api-reference/threadpool/#waitforcompletion","title":"WaitForCompletion","text":"<pre><code>WaitForCompletion(requireEmptyQueue: boolean?): void\n</code></pre> <p>Yields the current thread until all currently running tasks have completed. If <code>requireEmptyQueue</code> is <code>true</code>, also waits for the task queue to be empty. <code>requireEmptyQueue</code> is <code>true</code> by default.</p>"},{"location":"api-reference/threadpool/#waitforfreethread","title":"WaitForFreeThread","text":"<pre><code>WaitForFreeThread(): number\n</code></pre> <p>Yields the current thread until a free thread is available in the thread pool. If <code>AllowDispatchingToBusyThreads</code> is <code>true</code>, this method will return immediately.</p> <p>Returns the ID of the free thread.</p>"},{"location":"api-reference/threadpool/#waitforthread","title":"WaitForThread","text":"<pre><code>WaitForThread(threadId: number): void\n</code></pre> <p>Yields the current thread until the specified thread has completed all of its tasks. If <code>AllowDispatchingToBusyThreads</code> is <code>true</code>, this method will return immediately.</p>"},{"location":"api-reference/types/","title":"Types","text":"<p>Types exported by the <code>ThreadPool</code> module.</p>"},{"location":"api-reference/types/#enums","title":"Enums","text":""},{"location":"api-reference/types/#queuetype","title":"QueueType","text":"<pre><code>export type QueueType = \"FIFO\" | \"LIFO\"\n</code></pre> <p>The type of queue to use for a thread pool. (First-In-First-Out or Last-In-First-Out)</p>"},{"location":"api-reference/types/#objects","title":"Objects","text":""},{"location":"api-reference/types/#aggregatedthreadstates","title":"AggregatedThreadStates","text":"<pre><code>export type AggregatedThreadStates = {\n    Ready: number,\n    Running: number,\n    Setup: number\n}\n</code></pre> <p>A table containing the number of threads in each state. If a thread is initialized but isn't running a task, it is considered to be in the <code>Ready</code> state. If a thread is running at least one task, it is considered to be in the <code>Running</code> state. If a thread hasn't been initialized yet, it is considered to be in the <code>Setup</code> state. Uninitialized threads can not run tasks.</p>"},{"location":"api-reference/types/#threadpool","title":"ThreadPool","text":"<pre><code>export type ThreadPool = typeof(ThreadPool.new(ModuleScript, number, QueueType?, boolean?))\n</code></pre> <p>A thread pool that can run tasks concurrently on multiple threads.</p>"},{"location":"getting-started/best-practices/","title":"Best Practices and Optimization Tips","text":"<p>This section contains some useful information to keep in mind when working with Resync.</p>"},{"location":"getting-started/best-practices/#dispose-of-the-thread-pool","title":"Dispose of the thread pool","text":"<p>Since the thread pool contains references to Roblox Instances, the garbage collector won't automatically clean it up. This is why it's important to call <code>ThreadPool:Destroy()</code> when you're done using the thread pool to avoid memory leaks. This will clear the task queue, wait for all current tasks to finish and then cleans up the thread pool and all of its resources, allowing the garbage collector to reclaim the memory used by the thread pool.</p>"},{"location":"getting-started/best-practices/#parallelization-overhead","title":"Parallelization overhead","text":"<p>Like any parallel processing system (both software and hardware), Resync introduces some overhead when dispatching tasks to a thread pool. This is due to the computational cost of creating and managing threads, as well as the small amount of code used to execute the task itself. The amount of overhead is generally proportional to the number of tasks being executed, or O(n), where n is the number of tasks. Resync's optional Thread State Tracking feature also incurs some overhead caused by waiting for threads to finish before dispatching new tasks.</p>"},{"location":"getting-started/best-practices/#balance-the-workload","title":"Balance the workload","text":"<p>To minimize the effect of parallelization overhead, it is recommended to use Resync for tasks that are computationally expensive compared to the overhead and not feasible to run sequentially.</p> <p>For example, if you have a task that takes 1 second to run and you are running 1000 tasks, the overhead of Resync will be negligible compared to the total time taken to run all tasks, and the benefits of parallelization will be significant. However, if your task takes only a few microseconds to run, the overhead of Resync may outweigh any performance gains from parallelizing the task. If you have such a task, consider running it sequentially or grouping multiple tasks into a single task to reduce the impact of overhead. (e.g. generating a small area of voxel terrain instead of a single cell)</p> <p>In addition to using Resync for computationally expensive tasks, it is also important to keep the amount of work done by each task limited. If a task takes too long to run, it will slow down Roblox's parallel execution step, delaying the serial execution step and causing performance issues.</p>"},{"location":"getting-started/best-practices/#choose-the-right-number-of-threads","title":"Choose the right number of threads","text":"<p>The number of threads in the thread pool directly affects the amount of time spent executing a batch of tasks. If the number of threads is too low, some tasks will need to wait for a thread to become available, increasing the total time taken to execute all tasks. If the number of threads is too high for the current hardware, the threads will compete for resources, which may result in diminishing returns or even a decrease in performance.</p> <p>The optimal number of threads depends on the targeted hardware and frequency of task execution. A good starting point for a 4-core CPU is to use 64 threads. This number can be adjusted based on the number of cores available and the nature of the tasks being executed, but ultimately the best results will come from testing different thread counts and measuring the performance of the system.</p>"},{"location":"getting-started/best-practices/#use-thread-state-tracking-wisely","title":"Use Thread State Tracking wisely","text":"<p>As mentioned in the Thread Dispatching section, Thread State Tracking can be used to ensure that all threads have finished executing before dispatching new tasks. This feature can be useful in some cases, but it also introduces additional overhead. If you don't need to know exactly when all threads have finished executing, it is recommended to disable Thread State Tracking to reduce the overhead caused by waiting for threads to finish. This can also reduce the number of threads needed to achieve optimal performance.</p>"},{"location":"getting-started/best-practices/#dispatching-methods","title":"Dispatching methods","text":"<p>Resync's API provides several different methods for dispatching tasks that are best suited for different use cases.</p>"},{"location":"getting-started/best-practices/#use-the-right-method-for-the-job","title":"Use the right method for the job","text":"<p>Different task dispatching methods have different overheads and aren't universally optimal for all use cases. For example, if you have a constant stream of tasks that need to be executed and you don't need to know when they finish, using automatic dispatching is a good choice. For a more detailed comparison of the different dispatching methods, see the Thread Dispatching section.</p>"},{"location":"getting-started/best-practices/#pick-the-right-queue-type","title":"Pick the right queue type","text":"<p>Resync provides two different types of task queues: FIFO and LIFO. FIFO (First In, First Out) queues are best suited for tasks that need to be executed in the order they were added, while LIFO (Last In, First Out) queues are best suited for use cases when the newest tasks are more important than the older ones and should be dispatched first. Choosing the right queue type can help improve the performance of your system by ensuring that tasks are dispatched in the most efficient way.</p>"},{"location":"getting-started/generating-terrain/","title":"Generating Terrain","text":"<p>In this tutorial, we will set up a simple procedural terrain generator using Perlin noise. We will start by implementing it in a single thread, and then parallelize it later.</p> <p>Note that as procedural terrain generation is not the primary focus of this tutorial, we will keep the implementation simple and focus on the threading aspects, and explanations of the terrain generation algorithm will be minimal. The purpose of this article is to set up a simple example of a task that can be parallelized using Resync.</p>"},{"location":"getting-started/generating-terrain/#the-terrain-generator","title":"The terrain generator","text":"<p>We will use Luau's built-in <code>math.noise</code> function as our noise generator. To make parallelizing our terrain generation easier later, we will create a ModuleScript that returns a function that generates a single chunk of terrain. Let's call the ModuleScript <code>ChunkGenerator</code> and place it in <code>ServerScriptService</code>.</p> <pre><code>-- ServerScriptService.ChunkGenerator\n--!native\n\n-- Create an N-dimensional table where each dimension has a length of size.\n-- Initialize all elements in the table with elemValue.\nfunction makeNdArray(numDim, size, elemValue)\n    if numDim == 0 then\n        return elemValue\n    end\n    local result = {}\n    for i = 1, size do\n        result[i] = makeNdArray(numDim - 1, size, elemValue)\n    end\n    return result\nend\n\n-- Generate a chunk at the given chunk position (chunk position = absolute position / chunk size)\nreturn function(x: number, z: number, chunkSize: number, noiseScale: number)\n    -- Calculate the position of the -x,-z corner of the chunk\n    local absoluteX = x * chunkSize * 4\n    local absoluteZ = z * chunkSize * 4\n\n    -- Loop through all points in the chunk and calculate the height value\n    local materials = makeNdArray(3, chunkSize, Enum.Material.Grass)\n    local occupancy = makeNdArray(3, chunkSize, 0)\n\n    for x = 0, chunkSize - 1 do\n        for z = 0, chunkSize - 1 do\n            local noiseX = (absoluteX + x * 4) / noiseScale\n            local noiseZ = (absoluteZ + z * 4) / noiseScale\n\n            -- Set the base height to 10 and add a random amount to it with math.noise\n            local noise = math.noise(noiseX, noiseZ) * 10\n            local height = noise + 10\n\n            for y = 0, chunkSize - 1 do\n                local xIndex = x + 1\n                local yIndex = y + 1\n                local zIndex = z + 1\n\n                -- Set the occupancy at the current point\n                occupancy[xIndex][yIndex][zIndex] = math.clamp(height - y, 0, 1)\n            end\n        end\n    end\n\n    -- Set up the region for the chunk\n    local region = Region3.new(\n        Vector3.new(absoluteX, 0, absoluteZ),\n        Vector3.new(absoluteX + chunkSize * 4, chunkSize * 4, absoluteZ + chunkSize * 4)\n    )\n\n    -- Write the voxels\n    workspace.Terrain:WriteVoxels(region, 4, materials, occupancy)\nend\n</code></pre> <p>Next we'll set up a simple script that generates a region of terrain using the <code>TerrainGenerator</code> module.</p> <pre><code>local ServerScriptService = game:GetService(\"ServerScriptService\")\nlocal ChunkGenerator = require(ServerScriptService.ChunkGenerator)\n\nlocal areaSize = 32     -- The size of the area to generate in chunks\nlocal chunkSize = 32    -- The size of each chunk in voxels (4 studs per voxel)\n\nlocal startTime = os.clock()\nfor x = -areaSize // 2, areaSize // 2 do\n    for z = -areaSize // 2, areaSize // 2 do\n        ChunkGenerator(x, z, chunkSize, 100)\n    end\nend\nlocal endTime = os.clock()\n\nlocal timeTaken = endTime - startTime\nprint(\"Serial execution time:\", timeTaken)\n</code></pre>"},{"location":"getting-started/generating-terrain/#results","title":"Results","text":"<p>When you run the script, you should see the terrain appear after a few seconds. The script will print the time taken to generate the terrain in a single thread.</p> <p></p>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>Resync can be installed in two ways:</p>"},{"location":"getting-started/installation/#rojo-with-wally","title":"Rojo with Wally","text":"<ol> <li>Install Rojo and Wally.</li> <li>Add Resync as a dependency in your <code>wally.toml</code> file.    <pre><code>[dependencies]\nresync = \"tenx29/resync@1.0.1\"\n</code></pre></li> <li>Run <code>wally install</code>.</li> </ol>"},{"location":"getting-started/installation/#manually-in-roblox-studio","title":"Manually in Roblox Studio","text":"<ol> <li>Get the latest version of Resync from the Releases page or the Roblox Creator Store.</li> <li>Insert the model to your project and place it to the location of your choice. <code>ReplicatedStorage</code> is recommended as it allows both client and server code to access it.</li> <li>Require the Resync ThreadPool class in your code.    <pre><code>local ReplicatedStorage = game:GetService(\"ReplicatedStorage\")\nlocal ThreadPool = require(game.ReplicatedStorage.Resync.ThreadPool)\n</code></pre></li> <li>You're ready to start parallelizing your tasks! Refer to the API reference or follow the tutorial to get started.</li> </ol>"},{"location":"getting-started/parallel-terrain-generation/","title":"Parallel Terrain Generation","text":"<p>In this guide, we'll be parallelizing the terrain generation algorithm we implemented in the Generating Terrain tutorial. We'll be using Resync to generate multiple chunks of terrain in parallel.</p>"},{"location":"getting-started/parallel-terrain-generation/#parallelizing-the-chunk-generation","title":"Parallelizing the Chunk Generation","text":"<p>Resync requires a ModuleScript that returns a function to dispatch tasks to the thread pool, which is why we implemented the terrain generation like this in the previous tutorial. To make the <code>ChunkGenerator</code> script work with Resync, we'll need to modify it slightly.</p> <pre><code>-- ServerScriptService.ChunkGenerator\n--!native\n\n-- Create an N-dimensional table where each dimension has a length of size.\n-- Initialize all elements in the table with elemValue.\nfunction makeNdArray(numDim, size, elemValue)\n    if numDim == 0 then\n        return elemValue\n    end\n    local result = {}\n    for i = 1, size do\n        result[i] = makeNdArray(numDim - 1, size, elemValue)\n    end\n    return result\nend\n\n-- Generate a chunk at the given chunk position (chunk position = absolute position / chunk size)\nreturn function(_actor: Actor, _threadId: number, x: number, z: number, chunkSize: number, noiseScale: number)\n    task.desynchronize()\n\n    -- Calculate the position of the -x,-z corner of the chunk\n    local absoluteX = x * chunkSize * 4\n    local absoluteZ = z * chunkSize * 4\n\n    -- Loop through all points in the chunk and calculate the height value\n    local materials = makeNdArray(3, chunkSize, Enum.Material.Grass)\n    local occupancy = makeNdArray(3, chunkSize, 0)\n\n    for x = 0, chunkSize - 1 do\n        for z = 0, chunkSize - 1 do\n            local noiseX = (absoluteX + x * 4) / noiseScale\n            local noiseZ = (absoluteZ + z * 4) / noiseScale\n\n            -- Set the base height to 10 and add a random amount to it with math.noise\n            local noise = math.noise(noiseX, noiseZ) * 10\n            local height = noise + 10\n\n            for y = 0, chunkSize - 1 do\n                local xIndex = x + 1\n                local yIndex = y + 1\n                local zIndex = z + 1\n\n                -- Set the occupancy at the current point\n                occupancy[xIndex][yIndex][zIndex] = math.clamp(height - y, 0, 1)\n            end\n        end\n    end\n\n    -- Set up the region for the chunk\n    local region = Region3.new(\n        Vector3.new(absoluteX, 0, absoluteZ),\n        Vector3.new(absoluteX + chunkSize * 4, chunkSize * 4, absoluteZ + chunkSize * 4)\n    )\n\n    -- Write the voxels\n    task.synchronize()\n    workspace.Terrain:WriteVoxels(region, 4, materials, occupancy)\nend\n</code></pre> <p>The first two arguments <code>_actor</code> and <code>_threadId</code> are provided by Resync and can be used by the task function if information about the Actor object or the thread ID is needed. Since in this case we don't need them, we've prefixed them with an underscore to indicate that they're unused.</p> <p>Additionally we've added <code>task.desynchronize()</code> and <code>task.synchronize()</code> calls to the task function. These functions are built in to Luau and are used to switch execution between parallel and serial execution steps. In this case, we're doing the Perlin noise sampling (the slowest part of terrain generation) in parallel, and synchronize the task before writing the voxels to the terrain.</p> <p>Next, let's go back to the executing script and modify it to use a Resync thread pool to generate terrain in parallel.</p> <pre><code>local ServerScriptService = game:GetService(\"ServerScriptService\")\nlocal ChunkGenerator = require(ServerScriptService.ChunkGenerator)\nlocal ThreadPool = require(game.ReplicatedStorage.Resync.ThreadPool)\n\n-- Experiment with different values for these parameters\n-- to see how they affect performance\nlocal areaSize = 32\nlocal chunkSize = 32\nlocal numThreads = 64\n\nlocal pool = ThreadPool.new(script.Parent.ChunkGenerator, numThreads)\n\nlocal startTime = os.clock()\nfor x = -areaSize // 2, areaSize // 2 do\n    for z = -areaSize // 2, areaSize // 2 do\n        pool:Add(x, z, chunkSize, 100)\n    end\nend\npool:DispatchAll()\nlocal endTime = os.clock()\n\nlocal timeTaken = endTime - startTime\nprint(\"Parallel execution time:\", timeTaken)\n\n-- Since we know we won't be using the thread pool anymore, we should\n-- destroy it to free up resources\npool:Destroy()\n</code></pre> <p>In this script, we've created a new thread pool with a maximum of 64 worker threads and added tasks to the pool for each chunk to be generated. Note that the arguments we pass to <code>pool:Add</code> are the same as the arguments we pass to the <code>ChunkGenerator</code> function in serial implementation.</p> <p>Now when you run the script, you should see the terrain appear after a few seconds. The script will print the time taken to generate the terrain in parallel, and if you compare it to the serial execution time from the previous tutorial, the parallel execution time should be faster.</p> <p>The speedup you see will depend on several factors, such as the number of worker threads in the pool, the number of tasks, and the amount of work each task does. Try experimenting with different values for these parameters to see how they affect the performance of your terrain generation algorithm. Keep in mind that some workloads may be slower when executed in parallel due to the performance overhead of creating and managing threads.</p>"},{"location":"getting-started/thread-dispatching/","title":"Thread Dispatching","text":"<p>Resync provides 3 primary ways to dispatch tasks to the thread pool:</p> <ol> <li>One task at a time</li> <li>In batches of tasks from a queue</li> <li>Dynamically as tasks are added</li> </ol> <p>The method you choose depends on the nature of your tasks and how you want to manage them. Additionally, you can disable thread state tracking to reduce overhead when you don't need to track the state of tasks or know when they complete.</p>"},{"location":"getting-started/thread-dispatching/#choosing-the-right-method","title":"Choosing the Right Method","text":"<p>Note: The arguments used for dispatching threads in the code examples in this section are arbitrary and can be replaced with any values you need to pass to your task function. They do not affect how the thread pool dispatches the tasks.</p>"},{"location":"getting-started/thread-dispatching/#one-at-a-time","title":"One at a Time","text":"<p>The simplest way to dispatch tasks is to use the <code>ThreadPool:Dispatch</code> method. This method takes a variadic list of arguments to pass to the task function. The task function is then executed on the thread pool when a worker thread is available. This method gives you the finest control over task execution, allowing you to dispatch individual tasks as needed.</p> <pre><code>-- Yields until the task is complete\nmyThreadPool:Dispatch(\"synchronous dispatch\", 2, \"arg\")\n\n-- Only yields until the task is dispatched, does not wait for it to complete\nmyThreadPool:DispatchAsync(\"asynchronous dispatch\", 3, \"arg\")\n</code></pre>"},{"location":"getting-started/thread-dispatching/#in-batches","title":"In Batches","text":"<p>If you have a known group of tasks that you want to execute in parallel, you can use the <code>ThreadPool:Add</code> or <code>ThreadPool:AddBatch</code> and <code>ThreadPool:DispatchAll</code> methods. These methods allow you to add tasks to a queue and then dispatch them all at once. This can be useful if you want to execute a batch of tasks in parallel and then wait for all of them to complete before continuing.</p> <pre><code>-- Add tasks to the queue\nmyThreadPool:Add(\"task 1\", 1)\nmyThreadPool:Add(\"task 2\", 2)\nmyThreadPool:Add(\"task 3\", 3)\n\n-- Add a batch of tasks to the queue\nmyThreadPool:AddBatch({\n    {\"task 4\", 4},\n    {\"task 5\", 5},\n    {\"task 6\", 6},\n})\n\n-- Dispatch all tasks in the queue and yield until they are all complete\nmyThreadPool:DispatchAll()\n\n-- Asynchronous version of DispatchAll will only yield until all tasks are dispatched\nmyThreadPool:DispatchAllAsync()\n</code></pre>"},{"location":"getting-started/thread-dispatching/#dynamically","title":"Dynamically","text":"<p>For use cases where tasks are added to the queue over time, you can use the <code>ThreadPool:Add</code> or <code>ThreadPool:AddBatch</code> methods and set <code>ThreadPool.AutoDispatch</code> to <code>true</code>. This will automatically dispatch tasks as they are added to the queue. This approach is useful when you have a continuous stream of tasks that need to be executed in parallel, such as procedural generation.</p> <pre><code>-- Enable auto dispatching\nmyThreadPool.AutoDispatch = true\n\n-- Add tasks to the queue\nmyThreadPool:Add(\"task 1\", 1)\nmyThreadPool:Add(\"task 2\", 2)\nmyThreadPool:Add(\"task 3\", 3)\n\n-- Add a batch of tasks to the queue\nmyThreadPool:AddBatch({\n    {\"task 4\", 4},\n    {\"task 5\", 5},\n    {\"task 6\", 6},\n})\n\n-- There is no need to call DispatchAll, added tasks will be dispatched automatically\n</code></pre> <p>Note</p> <p>Unlike the other methods, dynamically dispatching tasks does not provide a way to wait for all tasks to complete. You can use <code>ThreadPool:WaitForCompletion</code>, but keep in mind that in the case of constant task addition, this method may cause your main thread to yield indefinitely if the task queue is never completed.</p>"},{"location":"getting-started/thread-dispatching/#thread-state-tracking","title":"Thread State Tracking","text":"<p>Experimental Feature</p> <p>Thread state tracking is still experimental. If the current implementation is found to be stable, <code>ThreadPool.AllowDispatchingToBusyThreads</code> may be removed in a future version of Resync.</p> <p>By default, Resync tracks the state of each task dispatched to the thread pool. This allows you to wait for tasks to complete, and allows Resync to only dispatch tasks to threads that are not currently busy. This tracking and management of thread state can introduce some overhead as tasks are dispatched and completed. If you don't need to track the state of tasks or know when they complete, you can disable thread state tracking by setting <code>ThreadPool.AllowDispatchingToBusyThreads</code> to <code>true</code>.</p> <pre><code>-- Create a thread pool with 2 threads and thread state tracking disabled\nlocal myThreadPool = ThreadPool.new(myWorkerScript, 2, \"FIFO\", true)\n-- You can also disable thread state tracking after creating the thread pool\n-- by setting myThreadPool.AllowDispatchingToBusyThreads = true\n\n-- Add more tasks than the thread pool size\nfor i = 1, 10 do\n    myThreadPool:Add(\"task \" .. i, i)\nend\n\n-- Dispatch all tasks in the queue\nmyThreadPool:DispatchAll()\n\n-- Since thread state tracking is disabled, all tasks will instantly be evenly\n-- distributed to the 2 worker threads\n</code></pre> <p>Warning</p> <p>Disabling thread state tracking will cause <code>ThreadPool:WaitForFreeThread</code> and <code>ThreadPool:WaitForThread</code> to return immediately, even if all threads are busy. <code>ThreadPool:WaitForCompletion</code> and synchronous dispatch methods will wait for the task queue to be empty, but may not reliably wait for all threads to complete their tasks after the queue is empty.</p>"},{"location":"getting-started/thread-dispatching/#benefits-of-thread-state-tracking","title":"Benefits of Thread State Tracking","text":"<ul> <li>Allows tracking of task state and completion. This makes it possible to fully use Resync's synchronous API.</li> <li>Ensures that tasks are dispatched in order and only to threads that are not busy.</li> </ul>"},{"location":"getting-started/thread-dispatching/#drawbacks-of-thread-state-tracking","title":"Drawbacks of Thread State Tracking","text":"<ul> <li>Increased performance overhead when dispatching tasks. Becomes apparent when the number of tasks dispatched exceeds the thread pool size.</li> </ul>"},{"location":"getting-started/tutorial-setup/","title":"Tutorial Setup","text":"<p>The following pages will show you can use Resync to parallelize a simple terrain generator. Before proceeding, it is recommended you do the following steps to set up a clean project with the necessary files.</p> <ol> <li>Create a new empty Baseplate place in Roblox Studio.</li> <li>Add Resync to your project and place it in <code>ReplicatedStorage</code>.</li> </ol>"},{"location":"getting-started/tutorial-setup/#disclaimer","title":"Disclaimer","text":"<p>This tutorial is only meant to showcase a simple example use case for Resync, and is not a comprehensive guide on how to use the library. For more information, refer to the API reference.</p>"},{"location":"getting-started/tutorial-setup/#next-steps","title":"Next Steps","text":"<ul> <li>Creating a terrain generator</li> <li>Parallelizing the terrain generator</li> <li>Best practices and optimization tips</li> </ul>"}]}